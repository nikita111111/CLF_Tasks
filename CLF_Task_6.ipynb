{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"news//news_train.txt\", encoding='utf-8') as f:\n",
    "    train  = f.readlines()\n",
    "with open(\"news//news_test.txt\", encoding='utf-8') as f:\n",
    "    test  = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'science': 2156,\n",
       "         'forces': 1225,\n",
       "         'culture': 2053,\n",
       "         'sport': 2215,\n",
       "         'media': 2111,\n",
       "         'life': 2033,\n",
       "         'economics': 2080,\n",
       "         'business': 554,\n",
       "         'style': 284,\n",
       "         'travel': 289})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter([line.split('\\t')[0] for line in train[:15000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenize(lines, regex_string=r'\\b\\w+\\b'):\n",
    "    result = []\n",
    "    for line in lines:\n",
    "        label, title, text = line.split('\\t')\n",
    "        \n",
    "        title = re.findall(regex_string, title.lower())\n",
    "        text = re.findall(regex_string, text.lower())\n",
    "        \n",
    "        result.append(dict())\n",
    "        result[-1]['label'] = label\n",
    "        result[-1]['title'] = title\n",
    "        result[-1]['text'] = text\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'science',\n",
       " 'title': ['британцы', 'секвенируют', 'геном', 'ричарда', 'iii'],\n",
       " 'text': ['британские',\n",
       "  'ученые',\n",
       "  'секвенируют',\n",
       "  'геном',\n",
       "  'ричарда',\n",
       "  'iii',\n",
       "  'об',\n",
       "  'этом',\n",
       "  'сообщает',\n",
       "  'the',\n",
       "  'guardian',\n",
       "  'секвенированием',\n",
       "  'называется',\n",
       "  'процесс',\n",
       "  'определения',\n",
       "  'аминокислотной',\n",
       "  'или',\n",
       "  'нуклеотидной',\n",
       "  'последовательности',\n",
       "  'молекулы',\n",
       "  'в',\n",
       "  'данном',\n",
       "  'случае',\n",
       "  'днк',\n",
       "  'по',\n",
       "  'данным',\n",
       "  'издания',\n",
       "  'стоимость',\n",
       "  'проекта',\n",
       "  'составляет',\n",
       "  '100',\n",
       "  'тысяч',\n",
       "  'фунтов',\n",
       "  'ученые',\n",
       "  'признают',\n",
       "  'что',\n",
       "  'чтение',\n",
       "  'генома',\n",
       "  'ричарда',\n",
       "  'iii',\n",
       "  'представляет',\n",
       "  'определенные',\n",
       "  'трудности',\n",
       "  'днк',\n",
       "  'приходится',\n",
       "  'извлекать',\n",
       "  'из',\n",
       "  'костей',\n",
       "  'которые',\n",
       "  'провели',\n",
       "  'в',\n",
       "  'земле',\n",
       "  'около',\n",
       "  '500',\n",
       "  'лет',\n",
       "  'король',\n",
       "  'был',\n",
       "  'похоронен',\n",
       "  'без',\n",
       "  'гроба',\n",
       "  'исследователи',\n",
       "  'говорят',\n",
       "  'что',\n",
       "  'их',\n",
       "  'целью',\n",
       "  'является',\n",
       "  'поиск',\n",
       "  'маркеров',\n",
       "  'которые',\n",
       "  'могли',\n",
       "  'бы',\n",
       "  'уточнить',\n",
       "  'внешний',\n",
       "  'вид',\n",
       "  'ричарда',\n",
       "  'iii',\n",
       "  'кроме',\n",
       "  'этого',\n",
       "  'их',\n",
       "  'интересуют',\n",
       "  'предрасположенности',\n",
       "  'короля',\n",
       "  'к',\n",
       "  'тем',\n",
       "  'или',\n",
       "  'иным',\n",
       "  'заболеваниям',\n",
       "  'по',\n",
       "  'окончании',\n",
       "  'проекта',\n",
       "  'геном',\n",
       "  'монарха',\n",
       "  'разместят',\n",
       "  'в',\n",
       "  'интернете',\n",
       "  'материалы',\n",
       "  'по',\n",
       "  'теме18',\n",
       "  '02',\n",
       "  '6',\n",
       "  'февраля',\n",
       "  '2013бесчестие',\n",
       "  'или',\n",
       "  'триумфанглийские',\n",
       "  'археологи',\n",
       "  'нашли',\n",
       "  'останки',\n",
       "  'ричарда',\n",
       "  'iiiостанки',\n",
       "  'ричарда',\n",
       "  'iii',\n",
       "  'были',\n",
       "  'обнаружены',\n",
       "  'в',\n",
       "  'конце',\n",
       "  '2012',\n",
       "  'года',\n",
       "  'в',\n",
       "  'начале',\n",
       "  '2013',\n",
       "  'года',\n",
       "  'ученые',\n",
       "  'установили',\n",
       "  'что',\n",
       "  'останки',\n",
       "  'действительно',\n",
       "  'принадлежат',\n",
       "  'монарху',\n",
       "  'для',\n",
       "  'проверки',\n",
       "  'они',\n",
       "  'сравнили',\n",
       "  'митохондриальную',\n",
       "  'днк',\n",
       "  'из',\n",
       "  'найденных',\n",
       "  'костей',\n",
       "  'с',\n",
       "  'мтднк',\n",
       "  'майкла',\n",
       "  'ибсена',\n",
       "  'канадца',\n",
       "  'который',\n",
       "  'считается',\n",
       "  'потомком',\n",
       "  'сестры',\n",
       "  'ричарда',\n",
       "  'iii',\n",
       "  'анны',\n",
       "  'король',\n",
       "  'ричард',\n",
       "  'iii',\n",
       "  'пробыл',\n",
       "  'на',\n",
       "  'троне',\n",
       "  'с',\n",
       "  '1483',\n",
       "  'по',\n",
       "  '1485',\n",
       "  'годы',\n",
       "  'он',\n",
       "  'был',\n",
       "  'убит',\n",
       "  'в',\n",
       "  'битве',\n",
       "  'при',\n",
       "  'босворте',\n",
       "  'ричард',\n",
       "  'был',\n",
       "  'последним',\n",
       "  'монархом',\n",
       "  'в',\n",
       "  'линии',\n",
       "  'плантагенетов',\n",
       "  'чтобы',\n",
       "  'взойти',\n",
       "  'на',\n",
       "  'престол',\n",
       "  'он',\n",
       "  'заключил',\n",
       "  'своих',\n",
       "  'малолетних',\n",
       "  'племянников',\n",
       "  'в',\n",
       "  'тауэр',\n",
       "  'где',\n",
       "  'они',\n",
       "  'погибли',\n",
       "  'при',\n",
       "  'невыясненных',\n",
       "  'обстоятельствах',\n",
       "  'более',\n",
       "  'всего',\n",
       "  'ричард',\n",
       "  'iii',\n",
       "  'известен',\n",
       "  'по',\n",
       "  'одноименной',\n",
       "  'пьесе',\n",
       "  'шекспира',\n",
       "  'в',\n",
       "  'которой',\n",
       "  'монарх',\n",
       "  'предстал',\n",
       "  'как',\n",
       "  'жестокий',\n",
       "  'злодей']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = tokenize(train)\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from tqdm.notebook import tqdm\n",
    "def lemmatize(lines):\n",
    "    morph_analyzer = pymorphy2.MorphAnalyzer()\n",
    "    for line in tqdm(lines):\n",
    "        line['title'] = list(map(lambda x: morph_analyzer.parse(x)[0].normal_form, line['title']))\n",
    "        line['text'] = list(map(lambda x: morph_analyzer.parse(x)[0].normal_form, line['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2643de4365b441b28a232c58c6c35440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 'science',\n",
       " 'title': ['британец', 'секвенировать', 'геном', 'ричард', 'iii'],\n",
       " 'text': ['британский',\n",
       "  'учёный',\n",
       "  'секвенировать',\n",
       "  'геном',\n",
       "  'ричард',\n",
       "  'iii',\n",
       "  'о',\n",
       "  'это',\n",
       "  'сообщать',\n",
       "  'the',\n",
       "  'guardian',\n",
       "  'секвенирование',\n",
       "  'называться',\n",
       "  'процесс',\n",
       "  'определение',\n",
       "  'аминокислотный',\n",
       "  'или',\n",
       "  'нуклеотидный',\n",
       "  'последовательность',\n",
       "  'молекула',\n",
       "  'в',\n",
       "  'дать',\n",
       "  'случай',\n",
       "  'днк',\n",
       "  'по',\n",
       "  'данные',\n",
       "  'издание',\n",
       "  'стоимость',\n",
       "  'проект',\n",
       "  'составлять',\n",
       "  '100',\n",
       "  'тысяча',\n",
       "  'фунт',\n",
       "  'учёный',\n",
       "  'признавать',\n",
       "  'что',\n",
       "  'чтение',\n",
       "  'геном',\n",
       "  'ричард',\n",
       "  'iii',\n",
       "  'представлять',\n",
       "  'определённый',\n",
       "  'трудность',\n",
       "  'днк',\n",
       "  'приходиться',\n",
       "  'извлекать',\n",
       "  'из',\n",
       "  'кость',\n",
       "  'который',\n",
       "  'провести',\n",
       "  'в',\n",
       "  'земля',\n",
       "  'около',\n",
       "  '500',\n",
       "  'год',\n",
       "  'король',\n",
       "  'быть',\n",
       "  'похоронный',\n",
       "  'без',\n",
       "  'гроб',\n",
       "  'исследователь',\n",
       "  'говорят',\n",
       "  'что',\n",
       "  'они',\n",
       "  'цель',\n",
       "  'являться',\n",
       "  'поиск',\n",
       "  'маркер',\n",
       "  'который',\n",
       "  'мочь',\n",
       "  'бы',\n",
       "  'уточнить',\n",
       "  'внешний',\n",
       "  'вид',\n",
       "  'ричард',\n",
       "  'iii',\n",
       "  'кроме',\n",
       "  'это',\n",
       "  'они',\n",
       "  'интересовать',\n",
       "  'предрасположенность',\n",
       "  'король',\n",
       "  'к',\n",
       "  'тем',\n",
       "  'или',\n",
       "  'иной',\n",
       "  'заболевание',\n",
       "  'по',\n",
       "  'окончание',\n",
       "  'проект',\n",
       "  'геном',\n",
       "  'монарх',\n",
       "  'разместить',\n",
       "  'в',\n",
       "  'интернет',\n",
       "  'материал',\n",
       "  'по',\n",
       "  'теме18',\n",
       "  '02',\n",
       "  '6',\n",
       "  'февраль',\n",
       "  '2013бесчестие',\n",
       "  'или',\n",
       "  'триумфанглийский',\n",
       "  'археолог',\n",
       "  'найти',\n",
       "  'останки',\n",
       "  'ричард',\n",
       "  'iiiостанки',\n",
       "  'ричард',\n",
       "  'iii',\n",
       "  'быть',\n",
       "  'обнаружить',\n",
       "  'в',\n",
       "  'конец',\n",
       "  '2012',\n",
       "  'год',\n",
       "  'в',\n",
       "  'начало',\n",
       "  '2013',\n",
       "  'год',\n",
       "  'учёный',\n",
       "  'установить',\n",
       "  'что',\n",
       "  'останки',\n",
       "  'действительно',\n",
       "  'принадлежать',\n",
       "  'монарх',\n",
       "  'для',\n",
       "  'проверка',\n",
       "  'они',\n",
       "  'сравнить',\n",
       "  'митохондриальный',\n",
       "  'днк',\n",
       "  'из',\n",
       "  'найти',\n",
       "  'кость',\n",
       "  'с',\n",
       "  'мтднк',\n",
       "  'майкл',\n",
       "  'ибсен',\n",
       "  'канадец',\n",
       "  'который',\n",
       "  'считаться',\n",
       "  'потомок',\n",
       "  'сестра',\n",
       "  'ричард',\n",
       "  'iii',\n",
       "  'анна',\n",
       "  'король',\n",
       "  'ричард',\n",
       "  'iii',\n",
       "  'пробыть',\n",
       "  'на',\n",
       "  'трон',\n",
       "  'с',\n",
       "  '1483',\n",
       "  'по',\n",
       "  '1485',\n",
       "  'год',\n",
       "  'он',\n",
       "  'быть',\n",
       "  'убитый',\n",
       "  'в',\n",
       "  'битва',\n",
       "  'при',\n",
       "  'босворт',\n",
       "  'ричард',\n",
       "  'быть',\n",
       "  'последний',\n",
       "  'монарх',\n",
       "  'в',\n",
       "  'линия',\n",
       "  'плантагенет',\n",
       "  'чтобы',\n",
       "  'взойти',\n",
       "  'на',\n",
       "  'престол',\n",
       "  'он',\n",
       "  'заключить',\n",
       "  'свой',\n",
       "  'малолетний',\n",
       "  'племянник',\n",
       "  'в',\n",
       "  'тауэр',\n",
       "  'где',\n",
       "  'они',\n",
       "  'погибнуть',\n",
       "  'при',\n",
       "  'невыясненный',\n",
       "  'обстоятельство',\n",
       "  'более',\n",
       "  'всего',\n",
       "  'ричард',\n",
       "  'iii',\n",
       "  'известный',\n",
       "  'по',\n",
       "  'одноимённый',\n",
       "  'пьеса',\n",
       "  'шекспир',\n",
       "  'в',\n",
       "  'который',\n",
       "  'монарх',\n",
       "  'предстать',\n",
       "  'как',\n",
       "  'жестокий',\n",
       "  'злодей']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(train_data)\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science</td>\n",
       "      <td>[британец, секвенировать, геном, ричард, iii]</td>\n",
       "      <td>[британский, учёный, секвенировать, геном, рич...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forces</td>\n",
       "      <td>[в, москва, задержать, сын, замглавы, лукойл]</td>\n",
       "      <td>[cын, вица, президент, компания, лукойл, русла...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forces</td>\n",
       "      <td>[новый, фигурант, болотный, дело, отправить, п...</td>\n",
       "      <td>[басманный, суд, москва, не, удовлетворить, хо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>culture</td>\n",
       "      <td>[мэрил, стрип, предложить, возглавить, идеальн...</td>\n",
       "      <td>[мэрил, стрип, предложить, роль, в, фильм, дав...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sport</td>\n",
       "      <td>[эксперт, сообщить, о, положительный, допинг, ...</td>\n",
       "      <td>[российский, боксёр, супертяжелый, весовой, ка...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                              title  \\\n",
       "0  science      [британец, секвенировать, геном, ричард, iii]   \n",
       "1   forces      [в, москва, задержать, сын, замглавы, лукойл]   \n",
       "2   forces  [новый, фигурант, болотный, дело, отправить, п...   \n",
       "3  culture  [мэрил, стрип, предложить, возглавить, идеальн...   \n",
       "4    sport  [эксперт, сообщить, о, положительный, допинг, ...   \n",
       "\n",
       "                                                text  \n",
       "0  [британский, учёный, секвенировать, геном, рич...  \n",
       "1  [cын, вица, президент, компания, лукойл, русла...  \n",
       "2  [басманный, суд, москва, не, удовлетворить, хо...  \n",
       "3  [мэрил, стрип, предложить, роль, в, фильм, дав...  \n",
       "4  [российский, боксёр, супертяжелый, весовой, ка...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.DataFrame(train_data)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('вулф', 0.8315575122833252), ('ха', 0.8252878785133362), ('бутырский', 0.8201467990875244), ('уилска', 0.8191892504692078), ('камбоджийский', 0.817003071308136), ('мохнаткин', 0.8169586062431335), ('циркач', 0.8144558668136597), ('терьер', 0.8128005266189575), ('слушаться', 0.8124203681945801), ('царнаева', 0.8119717836380005)] \n",
      "\n",
      "[('хоккей', 0.8957664966583252), ('теннис', 0.841028094291687), ('баскетбол', 0.7802850008010864), ('биатлон', 0.7438477873802185), ('фигурный', 0.7256494164466858), ('сборный', 0.7244349718093872), ('шахматы', 0.7181534767150879), ('сборная', 0.714941680431366), ('атлетика', 0.7119095325469971), ('первенство', 0.7014695405960083)] \n",
      "\n",
      "[('петербург', 0.7038277387619019), ('минск', 0.6358433961868286), ('крым', 0.6222398281097412), ('санкт', 0.6128217577934265), ('новосибирск', 0.6070311069488525), ('киев', 0.5775637626647949), ('столица', 0.5736709833145142), ('владивосток', 0.5727264881134033), ('столичный', 0.572583794593811), ('московский', 0.566883385181427)] \n",
      "\n",
      "[('автомобиль', 0.8021742701530457), ('самолёт', 0.7770984172821045), ('автомат', 0.7407158613204956), ('вертолёт', 0.7002742886543274), ('патрон', 0.6909617185592651), ('пассажир', 0.6872494220733643), ('кабина', 0.6850729584693909), ('лайнер', 0.6843569874763489), ('лёгкое', 0.647419810295105), ('пистолет', 0.6471344232559204)] \n",
      "\n",
      "[('сочи', 0.8210541009902954), ('ои', 0.8183085322380066), ('евровидение', 0.816181480884552), ('паралимпиада', 0.802824854850769), ('чм', 0.7944870591163635), ('олимпийский', 0.7926863431930542), ('рио', 0.7591657638549805), ('соревнование', 0.7537222504615784), ('турнир', 0.7092118263244629), ('оргкомитет', 0.684907078742981)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "word2vec = Word2Vec(train_df['text'].append(train_df['title']))\n",
    "\n",
    "words = [ 'Привет' , 'футбол' , 'москва', 'машина' , 'олимпиада']\n",
    "for word in words:\n",
    "    print(word2vec.wv.most_similar(positive=[word.lower()]),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'science': 0,\n",
       " 'forces': 1,\n",
       " 'culture': 2,\n",
       " 'sport': 3,\n",
       " 'media': 4,\n",
       " 'life': 5,\n",
       " 'economics': 6,\n",
       " 'business': 7,\n",
       " 'style': 8,\n",
       " 'travel': 9}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict  = {train_df.label.unique()[i] : i for i in range(train_df.label.nunique())}\n",
    "labels_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_labels(labels, labels_dict):\n",
    "    return labels.map(lambda label: labels_dict[label]).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def mean_tfidf_vectorizer(X, word2vec):\n",
    "    word2vec_dict = dict(zip(word2vec.wv.index2word, word2vec.wv.vectors))\n",
    "    dim = len(next(iter(word2vec_dict.values())))        \n",
    "    \n",
    "    tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "    tfidf.fit(X)\n",
    "    max_idf = max(tfidf.idf_)\n",
    "    word2weight = defaultdict(\n",
    "        lambda: max_idf, \n",
    "        [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "    \n",
    "    return np.array([\n",
    "        np.mean([word2vec[w] * word2weight[w] \n",
    "                 for w in words if w in word2vec] or \n",
    "                [np.zeros(dim)], axis=0) \n",
    "        for words in X\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = mean_tfidf_vectorizer(train_df['text'], word2vec)\n",
    "y_train = map_labels(train_df['label'], labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007d06d1051f4613b787edfb6806dedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = tokenize(test)\n",
    "\n",
    "lemmatize(test_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "x_test = mean_tfidf_vectorizer(test_df['text'], word2vec)\n",
    "y_test = map_labels(test_df['label'], labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8393333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = LogisticRegression(max_iter=100)\n",
    "clf.fit(x_train, y_train);\n",
    "predictions = clf.predict(x_test)\n",
    "print(f\"Accuracy score {accuracy_score(y_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8513333333333334\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(x_train, y_train);\n",
    "predictions = clf.predict(x_test)\n",
    "print(f\"Accuracy score {accuracy_score(y_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.7216666666666667\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train);\n",
    "predictions = clf.predict(x_test)\n",
    "print(f\"Accuracy score {accuracy_score(y_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
